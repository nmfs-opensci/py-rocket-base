---
reference-location: block
code-annotations: select
---

# Developer notes

## Design

py-rocket-base is inspired by [repo2docker](https://github.com/jupyterhub/repo2docker) and the [Pangeo Docker stack](https://pangeo-docker-images.readthedocs.io/en/latest/) design. py-rocker-base is built using repo2docker (via [repo2docker-action](https://github.com/jupyterhub/repo2docker-action)) and thus lets repo2docker make the choices regarding the environment design---things like how the conda environment is set-up and the base directory structure and permissions.

The Pangeo Docker stack does not use repo2docker, but mimics repo2docker's environment design. The Pangeo base-image behaves similar to repo2docker in that using the base-image in the `FROM` line of a Dockerfile causes the build to look for files with the same names as repo2docker's [configuration files](https://repo2docker.readthedocs.io/en/latest/config_files.html) and then do the proper action with those files. This means that routine users do not need to know how to write Dockerfile code in order to extend the image with new packages or applications. py-rocker-base Docker image uses this Pangeo base-image design. It is based on `ONBUILD` commands in the Dockerfile that trigger actions only when the image is used in the `FROM` line of another Dockerfile.

*There are many ways to install R and RStudio into an image designed for JupyterHubs* The objective of py-rocker-base is not to install R and RStudio, per se, and there are other leaner and faster ways to install R/RStudio if that is your goal[^1]. The objective of py-rocket-base is to create an JupyterHub image such when you click the RStudio button in the JupyterLab UI to enter the RStudio UI, you enter an environment that is the same as if you had used a Rocker image. If you are in the JupyterLab UI, the environment is the same as it you had used repo2docker (or Pangeo base-image) to create the environment.

[^1]: See for example [repo2docker-r](https://github.com/boettiger-lab/repo2docker-r) and [conda-r](https://github.com/binder-examples/r-conda) in [binder-examples](https://github.com/binder-examples).

## Documentation

To build the documentation book, clone repo and then

```
cd book
quarto render .
```

Set GitHub Pages to docs folder.

## repo2docker

[repo2docker-action](https://github.com/jupyterhub/repo2docker-action) is creating the image and publishing to `ghcr.io/nmfs-opensci/py-rocket-base` (image hosting like dockerhub or quay.io).

[repo2docker](https://github.com/jupyterhub/repo2docker) (a python package) sets up the structure of the base environment, e.g. installs mamba for package solving, sets up environment variables, installs linux packages, etc. It looks for specific files (like apt.txt, environment.yml, postBuild) in the build context (the repo that the Dockerfile is in) and takes the appropriate action. repo2docker-action also allows you to include `appendix` to add more commands to your Dockerfile. 

repo2docker does a lot behind the scene and has some different behavior.

### COPY

`COPY <src> <dest>` does not work in `appendix` because repo2docker changes the build context. The files are in `src` not `.`. In appendix, you do not do lines like this
```
COPY file1 newlocation/file1
```
to bring file1 into the build. Instead, the files are already in `${REPO_DIR}/`. If you want to copy a file to a new location, run the following as root if jovyan does not have permission to write to `newlocation`.
```
RUN cp ${REPO_DIR}/file1 newlocation/file1
```

### ENV and ARGS

repo2docker uses a number of ARGs in the build which you might expect to be in the image environment, for example `${NB_USER}`. These need to be converted to ENV to be available to child builds.

## RStudio

[jupyter-rsession-proxy](https://github.com/jupyterhub/jupyter-rsession-proxy) allows us to launch RStudio from Jupyter Lab, but the environment is different than the environment in Jupyter Lab.

### Environmental variables

* PATH is different. conda is not on the path.
* None of the environmental variables in the docker file will be in the `/rstudio` environment. The start command affects `\lab` and `\notebook` but not `\rstudio`.
* The path in the terminal (in RStudio) can/is different than in the R console. Expect weird unexpected behavior because of this. If you type `bash`, then `.bashrc` is run and that will run `conda init` and that will add conda binaries to the path. Then really weird and unexpected things can happen.

If you need some environmental variable set, you will need to set those in `$R_HOME/etc/Rprofile.site` which is run when R starts.

## Basic structure of py-rocket-base

The py-rocket-base docker build has the following structure:
```
# base image and environment
repo2docker sets this up
repo2docker-action sets the directory where the build files 
  are put to /srv/repo (via $REPO_DIR in GitHub Action)
  and ownership is set to jovyan (via $NB_USER)
  
# environment.yml
repo2docker adds these packages to the conda notebook environment

# start
repo2docker points the Docker image entrypoint (command run on start) to this file
${REPO_DIR}/start

# appendix
repo2docker-action adds the Docker commands here to the end of Dockerfile
most of the work in py-rocket-base is done here. appendix calls rocker.sh and install packages in apt2.txt
```

Each file is described below.

### apt2.txt

This is not named `apt.txt` because these packages need to be installed after R is installed because the R scripts uninstall packages as part of cleanup. There are some packages that are required for Desktop (`/desktop`) to operate correctly. Packages needed for R and RStudio building (`/rstudio`) are installed via the rocker install scripts.

### environment.yml

These are added to the notebook conda environment and in py-rocket-base the basic packages needed for Jupyter Lab, RStudio and Desktop are added. Scientific packages are not added here. They will be added via child images that use py-rocket-base as the base image (in the FROM line).


### appendix

This a long file with many pieces. The pieces are explained below. Click on the number next to code to read about what that code block does.


```r
USER root # <1>

# repo2docker does not set this. This is the default env in repo2docker type images
ENV CONDA_ENV=notebook # <2>

# Install R, RStudio via Rocker scripts
ENV R_VERSION="4.4.1"                                                      # <3>
ENV R_DOCKERFILE="verse_${R_VERSION}"  # <3>
# This is in the rocker script but will not run since ${NB_USER} already exists  # <3>
# Needed because rocker scripts set permissions based on the staff group  # <3>
RUN usermod -a -G staff "${NB_USER}"  # <3>
RUN PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin && \  # <3>
  chmod +x ${REPO_DIR}/rocker.sh && \  # <3>
  ${REPO_DIR}/rocker.sh  # <3>

# Install linux packages after R installation since the R install scripts get rid of packages  # <4>
# The package_list part is reading the file and doing clean-up to just have the list of packages  # <4>
RUN package_list=$(grep -v '^\s*#' ${REPO_DIR}/apt2.txt | grep -v '^\s*$' | sed 's/\r//g; s/#.*//; s/^[[:space:]]*//; s/[[:space:]]*$//' | awk '{$1=$1};1') && \  # <4>
  apt-get update && \  # <4>
  apt-get install --yes --no-install-recommends $package_list && \  # <4>
  apt-get autoremove --purge && \  # <4>
  apt-get clean && \  # <4>
  rm -rf /var/lib/apt/lists/*  # <4>
  
# Re-enable man pages disabled in Ubuntu 18 minimal image
# https://wiki.ubuntu.com/Minimal
RUN yes | unminimize # <5>
# NOTE: $NB_PYTHON_PREFIX is the same as $CONDA_PREFIX at run-time. # <5>
# $CONDA_PREFIX isn't available in this context. # <5>
# NOTE: Prepending ensures a working path; if $MANPATH was previously empty, # <5>
# the trailing colon ensures that system paths are searched. # <5>
ENV MANPATH="${NB_PYTHON_PREFIX}/share/man:${MANPATH}" # <5>
RUN mandb # <5>

# Add custom jupyter config. You can also put config.py files in the same place
COPY custom_jupyter_server_config.json ${NB_PYTHON_PREFIX}/etc/jupyter/jupyter_server_config.d/ # <6>
COPY custom_jupyter_server_config.json ${NB_PYTHON_PREFIX}/etc/jupyter/jupyter_notebook_config.d/ # <6>

# Clean up extra files in ${REPO_DIR}
RUN rm -rf ${REPO_DIR}/book ${REPO_DIR}/docs # <7>

###################
# Set up behavior for child dockerfiles
# Convert NB_USER to ENV (from ARG) so that it passes to the child dockerfile
ENV NB_USER=${NB_USER} # <8>

## ONBUILD section. These commands are run in child Dockerfiles. These are run right after the FROM image is loaded # <9>

ONBUILD USER ${NB_USER} # <10>

# ${REPO_DIR} is owned by ${NB_USER}
ONBUILD COPY --chown=${NB_USER}:${NB_USER} . ${REPO_DIR}/childimage # <11>


# Copy Desktop files into ${REPO_DIR}/Desktop if they exist. start will copy to Application dir and Desktop
# Will not fail if Desktop dir exists but is empty
ONBUILD RUN echo "Checking for 'Desktop directory'..." \ # <13>
        ; cd "${REPO_DIR}/childimage/" \ # <13>
        ; if test -d Desktop ; then \ # <13>
            mkdir -p "${REPO_DIR}/Desktop" && \ # <13>
            [ "$(ls -A Desktop 2>/dev/null)" ] && cp -r Desktop/* "${REPO_DIR}/Desktop/"; \ # <13>
        fi # <13>

# Install apt packages specified in a apt.txt file if it exists.
# blank lines and comments are supported in apt.txt
ONBUILD USER root # <14>
ONBUILD RUN echo "Checking for 'apt.txt'..." \ # <14>
        ; cd "${REPO_DIR}/childimage/" \ # <14>
        ; if test -f "apt.txt" ; then \ # <14>
        package_list=$(grep -v '^\s*#' apt.txt | grep -v '^\s*$' | sed 's/\r//g; s/#.*//; s/^[[:space:]]*//; s/[[:space:]]*$//' | awk '{$1=$1};1') \  # <14>
        && apt-get update --fix-missing > /dev/null \ # <14>
        && apt-get install --yes --no-install-recommends $package_list \ # <14>
        && apt-get autoremove --purge \ # <14>
        && apt-get clean \ # <14>
        && rm -rf /var/lib/apt/lists/* \ # <14>
        ; fi
ONBUILD USER ${NB_USER} # <15>

# Add the conda environment
# sometimes package solving will get rid of pip installed packages. Make sure jupyter-remote-desktop-proxy does not disappear
ONBUILD RUN echo "Checking for 'conda-lock.yml' or 'environment.yml'..." \ # <16>
        ; cd "${REPO_DIR}/childimage/" \ # <16>
        ; if test -f "conda-lock.yml" ; then echo "Using conda-lock.yml" & \ # <16>
        conda-lock install --name ${CONDA_ENV} \ # <16>
        && pip install --no-deps jupyter-remote-desktop-proxy \ # <16>
        ; elif test -f "environment.yml" ; then echo "Using environment.yml" & \ # <16>
        mamba env update --name ${CONDA_ENV} -f environment.yml  \ # <16>
        && pip install --no-deps jupyter-remote-desktop-proxy \ # <16>
        ; fi \ # <16>
        && mamba clean -yaf \ # <16>
        && find ${CONDA_DIR} -follow -type f -name '*.a' -delete \ # <16>
        && find ${CONDA_DIR} -follow -type f -name '*.js.map' -delete \ # <16>
        ; if ls ${NB_PYTHON_PREFIX}/lib/python*/site-packages/bokeh/server/static > /dev/null 2>&1; then \ # <16>
        find ${NB_PYTHON_PREFIX}/lib/python*/site-packages/bokeh/server/static -follow -type f -name '*.js' ! -name '*.min.js' -delete \ # <16>
        ; fi # <16>

# If a requirements.txt file exists, use pip to install packages
# listed there. We don't want to save cached wheels in the image
# to avoid wasting space.
ONBUILD RUN echo "Checking for pip 'requirements.txt'..." \ # <17>
        ; cd "${REPO_DIR}/childimage/" \ # <17>
        ; if test -f "requirements.txt" ; then \ # <17>
        ${NB_PYTHON_PREFIX}/bin/pip install --no-cache -r requirements.txt \ # <17>
        ; fi # <17>

# Add the r packages
ONBUILD RUN echo "Checking for 'install.R" \ # <18>
        ; cd "${REPO_DIR}/childimage/" \ # <18>
        ; if test -f "install.R" ; then echo "Using install.R" & \ # <18>
        Rscript install.R \ # <18>
        ; fi # <18>

# If a start file exists, put that under ${REPO_DIR}/childimage/start. 
# This is sourced in ${REPO_DIR}/start
ONBUILD RUN echo "Checking for 'start'..." \ # <19>
        ; cd "${REPO_DIR}/childimage/" \ # <19>
        ; if test -f "start" ; then \ # <19>
        chmod +x start \ # <19>
        ; fi # <19>

# If a postBuild file exists, run it!
# After it's done, we try to remove any possible cruft commands there
# left behind under $HOME - particularly stuff that jupyterlab extensions
# leave behind.
ONBUILD RUN echo "Checking for 'postBuild'..." \ # <20>
        ; cd "${REPO_DIR}/childimage/" \ # <20>
        ; if test -f "postBuild" ; then \ # <20>
        chmod +x postBuild \ # <20>
        && ./postBuild \ # <20>
        && rm -rf /tmp/* \ # <20>
        && rm -rf ${HOME}/.cache ${HOME}/.npm ${HOME}/.yarn \ # <20>
        && rm -rf ${NB_PYTHON_PREFIX}/share/jupyter/lab/staging \ # <20>
        && find ${CONDA_DIR} -follow -type f -name '*.a' -delete \ # <20>
        && find ${CONDA_DIR} -follow -type f -name '*.js.map' -delete \ # <20>
        ; fi # <20>

## End ONBUILD section for child images
################################

# Revert to default user and home as pwd
USER ${NB_USER}  # <21>
WORKDIR ${HOME} # <21>                                 
```
1. Some commands need to be run as root, such as installing linux packages with `apt-get`
2. repo2docker does not set this environment variable and it is useful for child builds
3. This section runs the script `rocker.sh` which installs R and RStudio using rocker scripts.
4. The rocker scripts build R from source and as part of clean up in the script, linux packages are removed that are not needed. repo2docker installs the packages in `apt.txt` automatically before the code in `appendix` thus the needed linux packages (which include packages for desktop) are put in `apt2.txt` (which repo2docker will not detect) and are installed separately here. The  `grep -v ` etc code is processing `apt2.txt` and removing comments and blank lines.
5. Ubuntu does not have man pages installed by default. These lines activate `man` so users have the common help files.
6. This is some custom jupyter config to allow hidden files to be listed in the folder browser.
7. `book` and `docs` are the documentation files and are not needed in the image.
8. The `NB_USER` environmental variable is not exported by repo2docker (it is an argument confined to the parent build) but is very useful for child builds. So it is converted to an environmental variable.
9. This next section is a series of `ONBUILD` commands. These are only run if py-rocker-base is used in the `FROM` line in a child docker file.
10. Set the user to NB_USER. Not strictly necessary but helps ensure that we don't accidentally create files that jovyan (NB_USER) cannot access.
11. Copy the child build context (files with the Docker file) into `${REPO_DIR}`. Make sure that jovyan owns the directory. Note, jovyan owns `${REPO_DIR}` (this is set by repo2docker).
12. empty
13. The Desktop files are put in a directory called Desktop. Copy them into `${REPO_DIR}/Desktop`. The start script will copy these into the correct location for the Desktop server.
14. If `apt.txt` is present, then install the packages. The code processes any comments or blank lines in `apt.txt`. This must be run as root so we switch to root to install.
15. Switch back to jovyan so we don't accidentally make files as belonging to root.
16. If `environment.yml` is present, install these into the conda environment and do some clean-up. Sometimes package solving will get rid of pip installed packages. We need to make sure that jupyter-remote-desktop-proxy does not disappear.
17. If `requirements.txt` is present, install with pip and do some clean-up.
18. `install.R` is an R script where the user can specify how to install packages or run any other R code.
19. `start` is run in the `${REPO_DIR}/start` command in a subshell. The `${REPO_DIR}/start` command cannot be replaced since it contains code to move the Desktop files into the correct place.
20. `postBuild` is a script. If present, run it and then do some clean-up. It is common to use `postBuild` to apply extensions or install packages that cannot be installed with `apt`.
21. The parent docker build completes by setting the user to jovyan and the working directory to `${HOME}`. Within a JupyterHub deployment, `${HOME}` will often be re-mapped to the user persistent memory so it is important not to write anything that needs to be persistent to `${HOME}`, for example configuration. You can do this in the `start` script since that runs after the user directory is mapped or you can put configuration files in some place other than `${HOME}`.

## rocker.sh

This script will copy in the rocker scripts from [rocker-versioned2](https://github.com/rocker-org/rocker-versioned2) into `${REPO_DIR}` to install things. It will read in one of the rocker docker files using `R_DOCKERFILE` defined in the `appendix` file (which is inserted into the main docker file). 
Variables defined here will only be available in this script. Click on the numbers in the script to learn what each section is doing.

```
#!/bin/bash
set -e

# Copy in the rocker files. Work in ${REPO_DIR} to make sure I don't clobber anything
cd ${REPO_DIR}   # <1>
wget https://github.com/rocker-org/rocker-versioned2/archive/refs/tags/R${R_VERSION}.tar.gz  # <1>
tar zxvf R${R_VERSION}.tar.gz && \  # <1>
mv rocker-versioned2-R${R_VERSION}/scripts /rocker_scripts && \  # <2>
ROCKER_DOCKERFILE_NAME="${R_DOCKERFILE}.Dockerfile"   # <3>
mv rocker-versioned2-R${R_VERSION}/dockerfiles/${ROCKER_DOCKERFILE_NAME}  /rocker_scripts/original.Dockerfile && \  # <3>
rm R${R_VERSION}.tar.gz && \  # <4>
rm -rf rocker-versioned2-R${R_VERSION}  # <4>

cd /   # <5>
# Read the Dockerfile and process each line   # <6>
while IFS= read -r line; do   # <6>
    # Check if the line starts with ENV or RUN   # <7>
    if [[ "$line" == ENV* ]]; then  # <7>
        # Assign variable  # <7>
        var_assignment=$(echo "$line" | sed 's/^ENV //g')  # <7>
        # Replace ENV DEFAULT_USER="jovyan"  # <8>
        if [[ "$var_assignment" == DEFAULT_USER* ]]; then  # <8>
            var_assignment="DEFAULT_USER=${NB_USER}"  # <8>
        fi  # <8>
        # Run this way eval "export ..." otherwise the " will get turned to %22
        eval "export $var_assignment"   # <9>
        # Write the exported variable to env.txt
        echo "export $var_assignment" >> ${REPO_DIR}/env.txt   # <10>
    elif [[ "$line" == RUN* ]]; then   # <11>
        # Run the command from the RUN line  # <11>
        cmd=$(echo "$line" | sed 's/^RUN //g')  # <11>
        echo "Executing: $cmd"  # <11>
        eval "$cmd" # || echo ${cmd}" encountered an error, but continuing..."  # <11>
    fi  # <11>
done < /rocker_scripts/original.Dockerfile  # <12>

# Install extra tex packages that are not installed by default  # <13>
if command -v tlmgr &> /dev/null; then  # <13>
    echo "Installing texlive collection-latexrecommended..."  # <13>
    tlmgr install collection-latexrecommended  # <13>
    tlmgr install pdfcol tcolorbox eurosym upquote adjustbox titling enumitem ulem soul rsfs  # <13>
fi  # <13>
```
1. The [rocker-versioned2](https://github.com/rocker-org/rocker-versioned2) repository for a particular R version is copied into `{REPO_DIR}` and unzipped. `R_VERSION` is defined in `appendix`.
2. The unzipped directory will be named `rocker-versioned2-R${R_VERSION}`. We move the `scripts` directory to `/rocker_scripts` (base level) because the rocker scripts expect the scripts to be there.
3. `R_DOCKERFILE` is defined as `verse_${R_VERSION}`. The docker file we will process (find ENV and RUN lines) is called `ROCKER_DOCKERFILE_NAME` in the rocker files. We move this to `/rocker_scripts/original.Dockerfile` so we can refer to it later.
4. Clean up the rocker directories that we no longer need.
5. cd to the base level where `/rocker_scripts` is.
6. The big while loop is processing `/rocker_scripts/original.Dockerfile`. The code is using piping `>` and the input file and pipe is specified at the end of the while loop code.
7. This looks if the line starts with `ENV` and if it does, it strips off `ENV` and stores the variable assigment statement to `$var_assignment`.
8. The rocker docker files do not use the `NB_USER` environmental variable (defined in `appendix`). If the `ENV` line is defining the default user, we need to change that assignment to the variable `NB_USER`. This part is specific to the rocker docker files.
9. We need to export any variables (`ENV`) found in the docker file so it is available to the scripts that will run in the `RUN` statements. We need to export the variables as done here (with `eval` and `export`) otherwise they don't make it to the child scripts about to be run. Getting variables to be exported to child scripts being called by a parent script is tricky and this line required a lot of testing and debugging to get variables exported properly.
10. The export line will only make the variable available to the child scripts. We also want them available in the final image. To do that, we write them to a file that we will source from the docker file. Scripts are run in an ephemeral subshell during docker builds so we cannot define the variable here.
11. If the docker file line starts with `RUN` then run the command. This command should be a rocker script because that is how rocker docker files are organized. See an example [rocker docker file](https://github.com/rocker-org/rocker-versioned2/blob/master/dockerfiles/verse_4.4.1.Dockerfile).
12. Here the input file for the while loop is specified.
13. The rocker `install_texlive.sh` script (which is part of verse) will provide a basic texlive installation. Here a few more packages are added so that the user is able to run vanilla Quarto to PDF and Myst to PDF. See the [chapter on texlive](tex.html).

## start

Within a JupyterHub, the user home directory `$HOME` is typically re-mapped to the user persistent home directory. That means that the image build process cannot put things into `$HOME`, they would just be lost when `$HOME` is re-mapped. If a process needs to have something in the home directory, e.g. in some local user configuration, this must be done in the `start` script. The repo2docker docker image specifies that the start script is `${REPO_DIR}/start`. 

For py-rocket-base, the start script is used to move the Desktop files (`*.desktop`) to where the Desktop server expects them, which is `${HOME}/.local/share/applications/` and `${HOME}/Desktop`. Any `*.desktop` files found there will appear as clickable icons in `\desktop`. This must be done in start, since the files need to be put in `${HOME}` which not available until after the server starts.

```
#!/bin/bash
set -euo pipefail

# Start - Set any environment variables here   # <1>
# These are inherited by all processes, *except* RStudio  # <1>
# USE export <parname>=value  # <1>
# Tell applications where to open desktop apps - this allows notebooks to pop open GUIs  # <1>
export DISPLAY=":1.0"  # <1>
# source this file to get the variables defined in the rocker Dockerfile  # <1>
source ${REPO_DIR}/env.txt  # <1>
# End - Set any environment variables here  # <1>

# The for loops will fail if they return null (no files). Set shell option nullglob
shopt -s nullglob  # <2>

# Add any .desktop files to the application database and desktop. This is done
# at startup-time because it's expected that a remote filesystem will be
# mounted at $HOME, which would overwrite the data if it was created at
# build-time.
APPLICATIONS_DIR="${HOME}/.local/share/applications"  # <3>
DESKTOP_DIR="${HOME}/Desktop"  # <3>
# Remove DESKTOP_DIR if it exists to avoid leftover files
if [ -d "${DESKTOP_DIR}" ]; then  # <4>
    rm -rf "${DESKTOP_DIR}"  # <4>
fi  # <4>
mkdir -p "${APPLICATIONS_DIR}"  # <5>
mkdir -p "${DESKTOP_DIR}"  # <5>
for desktop_file_path in ${REPO_DIR}/Desktop/*.desktop; do  # <6>
    cp "${desktop_file_path}" "${APPLICATIONS_DIR}/."  # <6>

    # Symlink application to desktop and set execute permission so xfce (desktop) doesn't complain
    desktop_file_name="$(basename ${desktop_file_path})"  # <7>
    # Set execute permissions on the copied .desktop file  # <7>
    chmod +x "${APPLICATIONS_DIR}/${desktop_file_name}"  # <7>
    ln -sf "${APPLICATIONS_DIR}/${desktop_file_name}" "${DESKTOP_DIR}/${desktop_file_name}"  # <8>
done
update-desktop-database "${APPLICATIONS_DIR}"  # <9>

# Add MIME Type data from XML files  to the MIME database.
MIME_DIR="${HOME}/.local/share/mime"  # <10>
MIME_PACKAGES_DIR="${MIME_DIR}/packages"  # <10>
mkdir -p "${MIME_PACKAGES_DIR}"  # <10>
for mime_file_path in ${REPO_DIR}/Desktop/*.xml; do  # <10>
    cp "${mime_file_path}" "${MIME_PACKAGES_DIR}/."  # <10>
done  # <10>
update-mime-database "${MIME_DIR}"  # <10>

# Run child start in a subshell to contain its environment
[ -f ${REPO_DIR}/childimage/start ] && ( source ${REPO_DIR}/childimage/start )  # <11>

exec "$@"
```